<div dir="ltr" style="text-align: left;" trbidi="on">
<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet"></link>
<style>
body{
    word-break: normal;
}
</style>
<p>
Harish Shanmugam, Senior Software Engineer, Altimetrik</p>
<p align="justify">
Experienced Software Engineer with demonstrated history of software development with broad based technical knowledge and in-depth understanding of SDLC phases.</p>
<h3 style="text-align: left;">
Highlights from Project Execution</h3>

<ul style="text-align: justify;">
<li>Having 4+ years of software development experience in Information Technology sector and having a solid understanding of various SDLC methodologies and software development best practices&nbsp;</li>
<li>Having experience with a strong foundation in programming languages <b>Java/J2EE</b>&nbsp;</li>
<li>Having experience in Big data technologies <b>Hadoop, Oozie, Hive, Pig, Kafka, Storm, Zookeeper</b> and NO-SQL database <b>Cassandra&nbsp;</b></li>
<li>Having self-driven experience on developing utility tools using <b>Swing, Linux Shell, Python</b></li>
<li>Having hands on experience in the frameworks <b>Hibernate</b>(ORM Tool), <b>Spring, RESTful web service (JAX-RS)&nbsp;</b></li>
<li>Having experience of working in AWS cloud services – EC2, <b>RDS, S3, ElasticCache (Redis)</b></li>
<li>Worked with traditional technologies <b>ActiveMQ, Quartz scheduler</b>&nbsp;</li>
<li>Having experience in the version control system tools <b>SVN </b>and <b>GIT&nbsp;</b></li>
<li>Worked with UI frameworks <b>Javascript, AJAX, JQuery, AngularJS, D3JS, Backbone JS and Handlebar JS&nbsp;</b></li>
<li>Worked with application servers <b>Apache tomcat, JBoss and Web Server Apache HTTP Server</b></li>
<li>Worked with building tools <b>Maven, ANT, Jenkin(CI)</b> and Maven repository <b>Nexus&nbsp;</b></li>
<li>Strong software developing expertise including <b>designing/modeling, programming/coding</b> of server side and client side components&nbsp;</li>
<li>Experienced in working with IDE like Eclipse&nbsp;</li>
<li>Having an experience in the OS platforms <b>Windows </b>and <b>Linux&nbsp;</b></li>
<li>More interested on technical <b>blog </b>writing </li>
</ul>
<h3 style="text-align: left;">
Educational Qualification</h3>
<ul style="text-align: left;">
<li><b>B.E (Computer Science Engineering)</b> in 2013 from Jeppiaar Maamallan Institute of Technology (Anna University), Chennai with <b>75.94%</b>&nbsp;</li>
<li><b>Diploma in Computer Engineering</b> in 2010 from Bhaktavatsalam Polytechnic College (DOTE), Kancheepuram with  <b>94.67%</b></li>
<li><b>SSLC </b>(Secondary School Leaving Certificate) in 2006 from Tamil Nadu State Board with <b>69.80 %
</b></li>
</ul>
<h3 style="text-align: left;">
Work Experience</h3>
<ul style="text-align: left;">
<li>Currently working as <b>Senior Software Engineer</b> at <b>Altimetrik India Private Limited</b>, Bangalore from March 2016</li>
<li>Worked as <b>Software Engineer</b> at E<b>xterro R&amp;D Private Limited</b>, Coimbatore from September 2014 to February 2016</li>
<li>Worked as <b>Software Engineer</b> at <b>BlackNGreen Mobile Solutions Private Limited</b>, Gurgaon from January 2013 to August 2014
</li>
</ul>
<h3 style="text-align: left;">
Technical Skills</h3>
<table class="table">
<tbody>
<tr>
<td>Primary Skills</td>
<td>Java, J2EE</td>
</tr>
<tr>
<td>Big Data Technologies</td>
<td>Hadoop (HDFS, MapReduce, Hive, Pig, Oozie, Zookeeper), Storm, Kafka and Cassandra</td>
</tr>
<tr>
<td>AWS Services</td>
<td>EC2, RDS, S3 and ElasticCache (Redis)</td>
</tr>
<tr>
<td>Other Languages</td>
<td>Java, Linux Shell Scripting, SQL, Python, C#.Net, VB.Net, C, C++</td>
</tr>
<tr>
<td>Technologies/ Frameworks</td>
<td>Java, Python, Hadoop, Hive, Pig, Oozie, Zookeeper, Linux Shell Scripting, Swing, Vertica, MySql, Maven, Spring,  AngularJS, D3JS, GIT, Jenkin, Nexus, Tidal</td>
</tr>
<tr>
<td>Java Technologies</td>
<td>Spring, Hibernate, Swing, JSP, Servlets, ActiveMQ, Quartz Scheduler, RESTful Web Service (JAX-RS), Most of the Logging frameworks and ApacheDS</td>
</tr>
<tr>
<td>Tools</td>
<td>Maven, Ant, Jenkins, Nexus</td>
</tr>
<tr>
<td>.Net Technologies</td>
<td>.Net Framework 4.0, Entity Framework</td>
</tr>
<tr>
<td>Operating System</td>
<td>Windows and Linux</td>
</tr>
<tr>
<td>Web Servers</td>
<td>Apache Tomcat, Apache Httpd Web Server and IIS </td>
</tr>
<tr>
<td>Databases</td>
<td>Microsoft SQL Server, Oracle, My SQL, Redis</td>
</tr>
<tr>
<td>Web Technologies</td>
<td>HTML, Java Script, AJAX, JQuery, AngularJS, D3JS, XML, CSS</td>
</tr>
<tr>
<td>IDE</td>
<td>Eclipse, NetBeans and Visual Studio </td>
</tr>
<tr>
<td>Version Control</td>
<td>SubVersion and GIT</td>
</tr>
</tbody>
</table>
<h3 style="text-align: left;">
Project Experiences</h3>
<!--------------------------------------------------------------------------------------------------------------------------------------------------------------->

<h4>
#1</h4>
<table class="table">
<tbody>
<tr>
<td>Company</td>
<td>Altimetrik India Private Limited (http://www.altimetrik.com/)</td>
</tr>
<tr>
<td>Client</td>
<td>Intuit Inc (https://www.intuit.com/)</td>
</tr>
<tr>
<td>Title</td>
<td>Data Engineering Platform</td>
</tr>
<tr>
<td>Duration</td>
<td>March 2016 to March 2017</td>
</tr>
<tr>
<td>Technologies/ Frameworks</td>
<td>Java, Python, Hadoop, Hive, Pig, Oozie, Zookeeper, Linux Shell Scripting, Swing, Vertica, MySql, Maven, Spring,  AngularJS, D3JS, GIT, Jenkin, Nexus, Tidal</td>
</tr>
<tr>
<td>Description</td>
<td>Data Engineering Platform is ETL data platform which collects data from various data sources like Hive, Kaka, API and Flat files and transforms raw data to business data. My team acts as a pipeline for Analytics team and other downstream teams which involves the creating/developing the micro services and provides multiple analytics with enormous data to Analyst team.</td>
</tr>
<tr>
<td>Role</td>
<td>Data Engineer</td>
</tr>
<tr>
<td>Responsibilities</td>
<td><ul>
<li>Involved in understanding, analyzing the requirements and development of various modules of Data Engineering Platform in different releases.</li>
<li>Migrated around 30 interfaces (400TB+ of historical and ongoing data -15 business hyper-critical) of various complexities and frequencies (hourly through weekly) from shared zone to isolated &amp; secured zone which included geographically distributed teams in 10 weeks</li>
<li>Developed data validation utility to fast validate the stability of the data environments and components by comparing the content and metadata across zones hence assuring the data reliability for the analyst community/data end users</li>
<li>Designed and developed Oozie workflows for Processing and computing web analytics data from Hive to Vertica</li>
<li>Worked with Data engineers and Analysts to automate the workload, processes and ensure the best and optimal scheduling for meeting crucial SLA</li>
<li>Analyzing and solving all technical problems faced by team</li>
<li>Handing of change requests and coordinating with onsite team to understand the requirements.</li>
<li>Voluntarily developed self service web applications for various project purposes like Managing Data Dictionary, Operations management site</li>
<li>Developing Data Visualization for daily performance metrics using AngularJS and D3JS</li>
<li>Participated on weekly Data Engineering Operations and acted as Primary On-Call support Deployment of the ETL Modules and Data Engineering Operations</li>
<li>Voluntarily documented the most of the ETL Data flows and Operation processes</li>
</ul>
</td>
</tr>
</tbody>
</table>
<!--------------------------------------------------------------------------------------------------------------------------------------------------------------->

<h4>
#2</h4>
<table class="table">
<tbody>
<tr>
<td>Company</td>
<td>Exterro R&amp;D (http://www.exterro.com/)</td>
</tr>
<tr>
<td>Title</td>
<td>Exterro Project and Employee Change Monitoring</td>
</tr>
<tr>
<td>Duration</td>
<td>September 2014 – February 2016</td>
</tr>
<tr>
<td>Technologies/ Frameworks</td>
<td>Java, J2EE, Rest Web Services, Hibernate, ActiveMQ, ApacheDS, JUnit, Maven, Ant, Jenkins, JQuery, Backbone JS, Handlebars JS, Storm, Kafka, Cassandra, Zookeeper, Supervisord, Redis, Linux Shell Scripts, AWS services (EC2, RDS, S3, ElasticCache(Redis)), Quartz, Hadoop, Windows SDK, Protocol Buffer, Cygwin and cmake</td>
</tr>
<tr>
<td>Description</td>
<td>Exterro Fusion is a project management application specifically designed for E-Discovery. It allows legal team to define E-Discovery project parameters, supervise progress, track deadlines, monitor budgets, manage schedule and evaluate vendor performance from within a single application. Fusion and Employee Change Monitor interoperates with corporate HR systems to detect employee status changes such as terminates, retirements, leave-of-absences and transfers. The system automatically applies user-defined actions which can include altering stakeholders or assigning tasks that direct them to take corrective actions such a initiating a data collection by conducting an interview. Fusion addresses all data management phases of e-discovery projects, including early case assessment, data collection, processing, analysis, review and production. Fusion crawls and indexes data in its native environment allowing users to run searches and analyze content prior to collecting data. It also allows users to automatically process, de-duplicate and cull data during the collection process. </td>
</tr>
<tr>
<td>Role</td>
<td>Full Stack Developer</td>
</tr>
<tr>
<td>Responsibilities</td>
<td><ul>
<li>Involved in understanding and analyzing the requirements, development of various modules in different releases</li>
<li>Processing the events in a continuous stream with Kafka, Storm and Cassandra </li>
<li>Worked on Employee Change Monitor module Amazon Cloud deployment</li>
<li>Done Proof of Concepts on Clustering the various Big data technologies such as  Storm, Cassandra, Kafka and Zookeeper, and Supervisord and successfully deployed for many clients.</li>
<li>Developed deploy Linux shell scripts for dynamic deployment of the above cluster services in the AWS EC2</li>
<li>Participated on SQL query optimization, by identifying the problematic query from the entire system</li>
<li>Participated on fixing deadlock issue caused by jar complexity</li>
<li>Developed Hadoop Stand-alone Build for Windows environment</li>
<li>Designed and Developed Active Directory Connector API and Integrated with Exterro Fusion for LDAP authentication and Data Integration</li>
<li>Involved on Client release certification and Bug Fixing</li>
</ul>
</td>
</tr>
</tbody>
</table>
<!--------------------------------------------------------------------------------------------------------------------------------------------------------------->

<h4>
#3</h4>
<table class="table">
<tbody>
<tr>
<td>Company</td>
<td>BlackNGreen India Private Limited (www.blackngreeen.com)</td>
</tr>
<tr>
<td>Title</td>
<td>Interactive Voice Response Platform</td>
</tr>
<tr>
<td>Duration</td>
<td>January 2013 - July 2013</td>
</tr>
<tr>
<td>Technologies/ Frameworks</td>
<td>Java, JSP, Spring MVC, Hibernate, Maven, Ant, ActiveMQ, Quartz Scheduler, Redis, Microsoft SQL Server 2008, VB.Net, C#.Net, C++ Socket Programming,  Hadoop, Hive and Linux Shell Scripts</td>
</tr>
<tr>
<td>Description</td>
<td>The platform that allows users to communicate to computer using any basic phones through voice and DTMF (Dual Tone Multi Frequency Signals). The platform provides the services such as Magic Voice, Magic Parrot, Religious Portals and Music Portals to the customers.</td>
</tr>
<tr>
<td>Role</td>
<td>Full Stack Developer</td>
</tr>
<tr>
<td>Responsibilities</td>
<td><ul>
<li>Involved on Analysis and Development of IVR platform from the crash with referring the existing system to additionally support different telephony hardware, operating system and to generate CDR(Call Dial Record) for Analysis</li>
<li>Bug-Fixing, Issue Tracking and Testing and Delivering to Deployment team</li>
<li>Designed and Developed Audio Stream recording module to record the audio stream from stream providers and encoded the audio format to support the IVR platform</li>
<li>Designed and Developed Content Distribution system to transfer the audio stream records to multiple telecom server local storages via FTP, SFTP</li>
<li>Designed and Developed VoiceXML parser to support VXML based IVR Call flows</li>
<li>Done Proof of Concepts on Distributed storage and implemented MySql DB Replication on the existing system</li>
<li>Done Proof of Concepts on Micro service frameworks such as MINA and Netty, and Torrent File Transfer mechanism</li>
<li>Analyzed and understood various logging frameworks such as SLF4J, Log4J, Log4J2, Log-back, and JCL and implemented in to the system</li>
<li>Done proof of concepts for IVR integration with Facebook and implemented it</li>
<li>Participated on design and developed of various modules such as Service Creation Module, Callback module, Out Bound Dial Scheduler, Content Manager</li>
<li>Voluntarily developed few utility tools for operation team like log filters, bulk content upload, data migration</li>
<li>Created documents and Trained Operational Team and Deployment Team about the IVR Platform</li>
<li>Done Proof of Concept for Business Intelligence module by collection Daily Call Dial Records from every server to Hadoop cluster via FTP to generate data insights</li>
</ul>
</td>
</tr>
</tbody>
</table>
</div>
